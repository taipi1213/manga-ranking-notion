#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Amazon ã‚³ãƒŸãƒƒã‚¯å£²ã‚Œç­‹ TOP20 ï¼‹ ã‚³ãƒŸãƒƒã‚¯ã‚·ãƒ¼ãƒ¢ã‚¢ 4ã‚«ãƒ†ã‚´ãƒª TOP20
= 100 ä»¶ã‚’æ¯æ—¥ Notion ã« upsertã€‚
ãƒ»ç”»åƒ URL ãŒå–ã‚Œãªãã¦ã‚‚è‡ªå‹•ã§ â€œç”»åƒãªã—â€ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
ãƒ»Notion API ãŒ 502/503 ã‚’è¿”ã—ã¦ã‚‚æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
"""

import os, time, datetime as dt, re, requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# â”€â”€ ç’°å¢ƒå¤‰æ•° (GitHub Secrets) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN = os.environ["NOTION_TOKEN"]
DB_ID = os.environ["NOTION_DB"]

HEAD = {
    "Authorization": f"Bearer {TOKEN}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json"
}
UA = {
    "User-Agent": "Mozilla/5.0",
    "Accept-Language": "ja-JP,ja;q=0.9"
}
TODAY = dt.date.today().isoformat()
HTTPS_IMG = re.compile(r"^https://.*\.(jpg|jpeg|png|webp)$", re.I)

# â”€â”€ Notion å…±é€šãƒªã‚¯ã‚¨ã‚¹ãƒˆ (3 å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def notion_request(method, url: str, **kw):
    for retry in range(3):
        resp = method(url, headers=HEAD, timeout=10, **kw)
        if resp.status_code < 500:              # 200ã€œ499 ã¯è¿”ã™
            return resp
        print(f"ğŸ”„  Retry {retry+1}/3 on {resp.status_code}")
        time.sleep(2 ** retry)                  # 1s â†’ 2s â†’ 4s
    resp.raise_for_status()                     # 3 å›å…¨éƒ¨ 5xx ãªã‚‰ä¾‹å¤–

# â”€â”€ Notion ãƒ˜ãƒ«ãƒ‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def file_obj(url: str) -> dict:
    return {
        "type": "external",
        "name": url.split("/")[-1] or "thumb.jpg",
        "external": {"url": url}
    }

def query_page(store, cat, rank):
    q = {"filter":{"and":[
        {"property":"Date","date":{"equals":TODAY}},
        {"property":"Store","select":{"equals":store}},
        {"property":"Category","select":{"equals":cat}},
        {"property":"Rank","number":{"equals":rank}}
    ]}}
    resp = notion_request(requests.post,
                          f"https://api.notion.com/v1/databases/{DB_ID}/query",
                          json=q)
    return resp.json()["results"]

def upsert(row):
    img_ok = HTTPS_IMG.match(row["thumb"]) is not None
    props = {
        "Date"    : {"date" : {"start": TODAY}},
        "Store"   : {"select": {"name": row["store"]}},
        "Category": {"select": {"name": row["cat"]}},
        "Rank"    : {"number": row["rank"]},
        "Title"   : {"title" : [{"text":{"content": row["title"]}}]},
        "URL"     : {"url"   : row["url"]},
        "Thumb"   : {"files" : [file_obj(row["thumb"])] if img_ok else []}
    }
    body = {"properties": props}
    if img_ok:
        body["cover"] = file_obj(row["thumb"])

    hit = query_page(row["store"], row["cat"], row["rank"])
    if hit:
        url  = f"https://api.notion.com/v1/pages/{hit[0]['id']}"
        resp = notion_request(requests.patch, url, json=body)
    else:
        body["parent"] = {"database_id": DB_ID}
        url  = "https://api.notion.com/v1/pages"
        resp = notion_request(requests.post, url, json=body)

    status = "with img" if img_ok else "no img "
    print(f"âœ… {row['title'][:28]} ({status})")

# â”€â”€ Amazon â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def amazon_thumb(detail):
    try:
        s = BeautifulSoup(requests.get(detail, headers=UA, timeout=10).text,
                          "html.parser")
        og = s.find("meta", property="og:image")
        if og and "https://" in og["content"]:
            return og["content"].replace("_SX160_", "_SX600_")
    except Exception:
        pass
    return ""

def fetch_amazon(limit=20):
    base = "https://www.amazon.co.jp"
    s = BeautifulSoup(
        requests.get(f"{base}/gp/bestsellers/books/2278488051",
                     headers=UA, timeout=10).text, "html.parser")
    for rank, div in enumerate(s.select("div.zg-grid-general-faceout")[:limit], 1):
        img   = div.select_one("img[alt]")
        title = img["alt"].strip() if img else f"A-Rank{rank}"
        a_tag = div.find_parent("a") or div.select_one("a[href]")
        href  = urljoin(base, a_tag["href"]) if a_tag else base
        yield {"store":"Amazon","cat":"ã‚³ãƒŸãƒƒã‚¯å£²ã‚Œç­‹","rank":rank,
               "title":title,"url":href,"thumb":amazon_thumb(href)}

# â”€â”€ ã‚³ãƒŸãƒƒã‚¯ã‚·ãƒ¼ãƒ¢ã‚¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def cmoa_thumb(li):
    img = li.select_one("img[src]")
    if not img:
        return ""
    src = img["src"]
    return "https:" + src if src.startswith("//") else src

def fetch_cmoa(cat, url, limit=20):
    s = BeautifulSoup(requests.get(url, headers=UA, timeout=10).text,
                      "html.parser")
    for i, li in enumerate(
          s.select("ul#ranking_result_list li.search_result_box")[:limit], 1):
        title = li.select_one("img[alt]")["alt"].strip()
        href  = urljoin("https://www.cmoa.jp", li.select_one("a.title")["href"])
        yield {"store":"Cmoa","cat":cat,"rank":i,
               "title":title,"url":href,"thumb":cmoa_thumb(li)}

CATS = [
    ("ç·åˆ",         "https://www.cmoa.jp/search/purpose/ranking/all/"),
    ("å°‘å¹´ãƒãƒ³ã‚¬",   "https://www.cmoa.jp/search/purpose/ranking/boy/"),
    ("é’å¹´ãƒãƒ³ã‚¬",   "https://www.cmoa.jp/search/purpose/ranking/gentle/"),
    ("ãƒ©ã‚¤ãƒˆã‚¢ãƒ€ãƒ«ãƒˆ","https://www.cmoa.jp/search/purpose/ranking/sexy/")
]

# â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("=== START", dt.datetime.now())
    for r in fetch_amazon():
        upsert(r); time.sleep(0.5)          # Notion 3 rps åˆ¶é™
    for cat, url in CATS:
        for r in fetch_cmoa(cat, url):
            upsert(r); time.sleep(0.5)
    print("=== DONE ", dt.datetime.now())
